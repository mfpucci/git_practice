{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4fd0af9f7d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df.drop(['price'],axis=1)\n",
    "y = df.price\n",
    "\n",
    "linreg, y_pred, y_test = linear_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "def linear_regression(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    \n",
    "    # Errors\n",
    "    print('R^2 Score:',round(linreg.score(X, y),2))\n",
    "    print('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),5))\n",
    "    print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),5))\n",
    "    print('-----------------------------------')\n",
    "    print('Average Predicted Price:', round(y_pred.mean(),4))\n",
    "    print('Average Actual Price:', round(y_test.mean(), 4))\n",
    "    \n",
    "    # Visualization of selection of 100 house prices\n",
    "    plt.figure(figsize=(16,6))\n",
    "    sns.lineplot(range(len(y_pred[:200])), y_pred[:200], label='Predicted Prices')\n",
    "    sns.lineplot(range(len(y_pred[:200])), y_test[:200], label='Actual Prices')\n",
    "    plt.title('Comparing predicted price vs actual price', fontdict={'fontsize': 20}), plt.xlabel('Values'), plt.ylabel('Prices')\n",
    "    plt.legend(), plt.show()\n",
    "    return (linreg, y_pred, y_test)\n",
    "\n",
    "def cross_validation(X, y, cv=15, show_scores=False):\n",
    "    score = cross_val_score(linreg, X, y, cv=cv, scoring=\"r2\")\n",
    "    print('Model Accuracy:',round(sum(score)/len(score),2)*100, '%')\n",
    "    print(score) if show_scores else False\n",
    "    \n",
    "def feature_selection(X, y):\n",
    "    est = sm.OLS(y, X).fit()\n",
    "    pvalues = pd.DataFrame(est.pvalues, columns=['p'])\n",
    "    features = list(pvalues[pvalues.p < 0.05].index)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "#We will now split our data into a train and test set using an initial test size of 0.25. We will then use the stepwise function above to do an interative feature selection for all of the independent variables. For each iteration, one more predictor will be selected and added, and in addition, a repeated k-fold with 3 splits and 10 repeats will be ran to cross validate the R-squared value and % difference in MSE between the train and test set for each regression. Then, by graphing a plot of our predicted y-values vs the actual y-values and comparing the R-squared values and % differences in MSE, we should be able to decide which predictors to include in our model of best fit.'\n",
    "#RFE regression of all predictors using repeated k-fold \n",
    "\n",
    "#setting X, y and creating train/test split\n",
    "X = df.drop(['non_log_price', 'price'], axis=1)\n",
    "y = df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=47)\n",
    "\n",
    "#initializing counter variable 'i' and creating lists to add to over each iteration\n",
    "i = 1\n",
    "results_df = pd.DataFrame()\n",
    "predictors = list()\n",
    "reg_score = list()\n",
    "mse_diffs = list()\n",
    "added_pred = list()\n",
    "previous_columns = []\n",
    "\n",
    "#this loop repeats once for each column in 'df'\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "while i <= (int(len(df.drop(['non_log_price', 'price'], axis=1).columns))):\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=3, n_repeats=10, random_state=47)\n",
    "    scores = 0\n",
    "    percent_diffs = 0\n",
    "    \n",
    "    #this loop using a repeated k-fold to generate an average R-squared and % difference in train/test MSE \n",
    "for train_index, test_index in rkf.split(X_train1):\n",
    "        X_train2, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train2, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        linreg1 = LinearRegression()\n",
    "        selector = RFE(linreg, n_features_to_select = i)\n",
    "        selector1 = selector.fit(X_train2, y_train2) \n",
    "        selected_columns = X_train2.columns[selector.support_ ]\n",
    "        linreg1.fit(X_train2[selected_columns],y_train2)\n",
    "        scores = scores + linreg.score(X_test[selected_columns], y_test)\n",
    "        y_hat_train = linreg.predict(X_train[selected_columns])\n",
    "        y_hat_test = linreg.predict(X_test[selected_columns])\n",
    "        train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "        test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "        mse_diff = test_mse - train_mse\n",
    "        percent_diff = mse_diff/train_mse\n",
    "        percent_diffs += percent_diff\n",
    "        \n",
    "        \n",
    " #adding data to lists\n",
    "predictors.append(i)\n",
    "reg_score.append(scores/30)\n",
    "mse_diffs.append(percent_diffs/30*100)\n",
    "added_pred.append(list(set(selected_columns) - set(previous_columns)))\n",
    "previous_columns = selected_columns\n",
    "predicted = linreg.predict(X_test[selected_columns])\n",
    "\n",
    "#creating a plot of predicted values vs actual values\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "#ax.scatter(y_test, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot(y_test, y_test, 'k--', lw=4, color='y')\n",
    "sns.regplot(x=y_test, y=predicted, ax=ax, line_kws={\"color\": \"red\"})\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title(str(i) + \" Predictors\")\n",
    "ax.legend()\n",
    "\n",
    "results_df['# Predictors'] = predictors\n",
    "results_df['R-squared'] = reg_score\n",
    "results_df['MSE % Difference'] = mse_diffs\n",
    "results_df['Added Predictor'] = added_pred\n",
    "plt.show()\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(y_test, y_test, lw=4, color='y')\n",
    "sns.regplot(x=y_test, y=predicted, ax=ax)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "ax.set_title(str(i) + \"Predictors\")\n",
    "ax.legend()\n",
    "\n",
    "results_df['Model Predictors'] = predictors\n",
    "results_df['R-squared Value'] = reg_score\n",
    "results_df['Mean Sq. Error and Difference'] = mse_diffs\n",
    "results_df['Additional Predictors'] = added_pred\n",
    "plt.show()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while changed:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
